{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "133227e6",
   "metadata": {},
   "source": [
    "### 1. What do REGION PROPOSALS entail?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a261aa4",
   "metadata": {},
   "source": [
    "Region proposal is about finding regions with a high probability of containing interesting information. By interesting information I mean information relevant to the task. A Region Proposal Network, or RPN, is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c767296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a12203b0",
   "metadata": {},
   "source": [
    "### 2. What do you mean by NON-MAXIMUM SUPPRESSION? (NMS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29186e74",
   "metadata": {},
   "source": [
    "Non Maximum Suppression (NMS) is a technique used in numerous computer vision tasks. It is a class of algorithms to select one entity (e.g., bounding boxes) out of many overlapping entities. We can choose the selection criteria to arrive at the desired results. Non max suppression is a technique used mainly in object detection that aims at selecting the best bounding box out of a set of overlapping boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5c6376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64d79806",
   "metadata": {},
   "source": [
    "### 3. What exactly is mAP?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968f3065",
   "metadata": {},
   "source": [
    "In computer vision, mAP is a popular evaluation metric used for object detection (i.e. localisation and classification). Localization determines the location of an instance (e.g. bounding box coordinates) and classification tells you what it is (e.g. a dog or cat).\n",
    "\n",
    "To evaluate object detection models like R-CNN and YOLO, the mean average precision (mAP) is used. The mAP compares the ground-truth bounding box to the detected box and returns a score. The higher the score, the more accurate the model is in its detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d71cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fce9564",
   "metadata": {},
   "source": [
    "### 4. What is a frames per second (FPS)?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8ef5b4",
   "metadata": {},
   "source": [
    "Frames per second (FPS) is a unit that measures display device performance. It consists of the number of complete scans of the display screen that occur each second. This is the number of times the image on the screen is refreshed each second, or the rate at which an imaging device produces unique sequential images called frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687d800e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc085ad6",
   "metadata": {},
   "source": [
    "### 5. What is an IOU (INTERSECTION OVER UNION)?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8ba2ba",
   "metadata": {},
   "source": [
    "Intersection over Union (IoU) is used when calculating mAP. It is a number from 0 to 1 that specifies the amount of overlap between the predicted and ground truth bounding box.\n",
    "Intersect over Union (IoU) is a metric that allows us to evaluate how similar our predicted bounding box is to the ground truth bounding box. The idea is that we want to compare the ratio of the area where the two boxes overlap to the total combined area of the two boxes. The formula for calculating IoU is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3133e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e631e635",
   "metadata": {},
   "source": [
    "### 6. Describe the PRECISION-RECALL CURVE (PR CURVE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b0fcc9",
   "metadata": {},
   "source": [
    "A PR curve is simply a graph with Precision values on the y-axis and Recall values on the x-axis. In other words, the PR curve contains TP/(TP+FN) on the y-axis and TP/(TP+FP) on the x-axis. It is important to note that Precision is also called the Positive Predictive Value. The precision-recall curve shows the tradeoff between precision and recall for different threshold. A high area under the curve represents both high recall and high precision, where high precision relates to a low false positive rate, and high recall relates to a low false negative rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef612c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6950b15f",
   "metadata": {},
   "source": [
    "### 7. What is the term \"selective search\"?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399dc0ac",
   "metadata": {},
   "source": [
    "Selective Search is a region proposal algorithm used in object detection. It is designed to be fast with a very high recall. It is based on computing hierarchical grouping of similar regions based on color, texture, size and shape compatibility. This article looks into selective search algorithm which uses both Exhaustive search and segmentation (a method to separate objects of different shapes in the image by assigning them different colors). Algorithm Of Selective Search, We use Greedy algorithm to combine similar regions to make larger regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70928ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "092ed0a0",
   "metadata": {},
   "source": [
    "### 8. Describe the R-CNN model's four components.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7031be",
   "metadata": {},
   "source": [
    "nstead of working on a massive number of regions, the RCNN algorithm proposes a bunch of boxes in the image and checks if any of these boxes contain any object. RCNN uses selective search to extract these boxes from an image (these boxes are called regions).\n",
    "\n",
    "Let’s first understand what selective search is and how it identifies the different regions. There are basically four regions that form an object: varying scales, colors, textures, and enclosure. Selective search identifies these patterns in the image and based on that, proposes various regions. Here is a brief overview of how selective search works:\n",
    "\n",
    "* It first takes an image as input:\n",
    "\n",
    "* Then, it generates initial sub-segmentations so that we have multiple regions from this image:\n",
    "\n",
    "* The technique then combines the similar regions to form a larger region (based on color similarity, texture similarity, size similarity, and shape compatibility):\n",
    "\n",
    "* Finally, these regions then produce the final object locations (Region of Interest).\n",
    "Below is a succint summary of the steps followed in RCNN to detect objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6809d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72f73f45",
   "metadata": {},
   "source": [
    "### 9. What exactly is the Localization Module?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd35b8d8",
   "metadata": {},
   "source": [
    "Localization and Object detection are two of the core tasks in Computer Vision , as they are applied in many real-world applications such as Autonomous vehicles and Robotics. So, if you want to work in these industries as a Computer vision specialist or you want to build a relative product , you better have a good grasp of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5c9ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4feaa923",
   "metadata": {},
   "source": [
    "### 10. What are the R-CNN DISADVANTAGES?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa3191d",
   "metadata": {},
   "source": [
    "we’ve seen how RCNN can be helpful for object detection. But this technique comes with its own limitations. Training an RCNN model is expensive and slow thanks to the below steps:\n",
    "\n",
    "* Extracting 2,000 regions for each image based on selective search\n",
    "* Extracting features using CNN for every image region. Suppose we have N images, then the number of CNN features will be N*2,000\n",
    "* The entire process of object detection using RCNN has three models:\n",
    "    1. CNN for feature extraction\n",
    "    2. Linear SVM classifier for identifying objects\n",
    "    3. Regression model for tightening the bounding boxes.\n",
    "\n",
    "All these processes combine to make RCNN very slow. It takes around 40-50 seconds to make predictions for each new image, which essentially makes the model cumbersome and practically impossible to build when faced with a gigantic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5f2a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
